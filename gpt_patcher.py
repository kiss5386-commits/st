#!/usr/bin/env python3
"""
GPT ìë™ ì½”ë“œ íŒ¨ì¹˜ ë„êµ¬ - ê°œì„ ëœ í† í° ê´€ë¦¬ ë²„ì „
ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì´ˆê³¼ ë¬¸ì œë¥¼ í•´ê²°í•˜ê³  ëŒ€ìš©ëŸ‰ íŒŒì¼ ì²˜ë¦¬ ëŠ¥ë ¥ ê°•í™”
"""

import os
import json
import yaml
import subprocess
import time
import logging
from pathlib import Path
from typing import Dict, List, Optional, Tuple
import openai

# ===== ì„¤ì • =====
OPENAI_MODEL = "gpt-3.5-turbo"  # ê¸°ë³¸ ëª¨ë¸ (ì»¨í…ìŠ¤íŠ¸ ê¸¸ì´ ì œí•œ ëŒ€ì‘)
MAX_CONTEXT_TOKENS = 6000       # ì•ˆì „ ë§ˆì§„ ê³ ë ¤í•œ ìµœëŒ€ í† í°
MAX_COMPLETION_TOKENS = 2000    # ì‘ë‹µ í† í° ì œí•œ
RETRY_ATTEMPTS = 3
RETRY_DELAY = 2

# ì¶”ì í•  íŒŒì¼ íŒ¨í„´
TRACKED_PATTERNS = [
    "*.py", "*.js", "*.ts", "*.html", "*.css", "*.json", "*.yml", "*.yaml",
    "*.md", "*.txt", "*.sh", "*.bat", "*.sql", "*.env", "*.ini", "*.cfg"
]

# ë¬´ì‹œí•  ë””ë ‰í† ë¦¬/íŒŒì¼
IGNORE_PATTERNS = [
    ".git", "__pycache__", "node_modules", ".venv", "venv", 
    "build", "dist", ".pytest_cache", ".idea", ".vscode"
]

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)

class TokenManager:
    """í† í° ì‚¬ìš©ëŸ‰ ê´€ë¦¬ ë° ì»¨í…ìŠ¤íŠ¸ ìµœì í™”"""
    
    @staticmethod
    def estimate_tokens(text: str) -> int:
        """í…ìŠ¤íŠ¸ì˜ ëŒ€ëµì ì¸ í† í° ìˆ˜ ì¶”ì • (1í† í° â‰ˆ 4ê¸€ì)"""
        return len(text) // 3  # ë³´ìˆ˜ì  ì¶”ì •
    
    @staticmethod
    def truncate_content(content: str, max_tokens: int) -> str:
        """ì»¨í…ì¸ ë¥¼ í† í° ì œí•œì— ë§ê²Œ ì˜ë¼ëƒ„"""
        estimated_tokens = TokenManager.estimate_tokens(content)
        if estimated_tokens <= max_tokens:
            return content
        
        # ëŒ€ëµì  ë¹„ìœ¨ë¡œ ì˜ë¼ë‚´ê¸°
        ratio = max_tokens / estimated_tokens
        truncate_length = int(len(content) * ratio * 0.9)  # ì•ˆì „ ë§ˆì§„
        
        truncated = content[:truncate_length]
        return truncated + "\n\n[... ë‚´ìš©ì´ ê¸¸ì–´ ì¼ë¶€ ìƒëµë¨ ...]"
    
    @staticmethod
    def optimize_file_list(files: List[Dict], max_tokens: int) -> List[Dict]:
        """íŒŒì¼ ëª©ë¡ì„ í† í° ì œí•œì— ë§ê²Œ ìµœì í™”"""
        total_tokens = 0
        optimized_files = []
        
        # ì‘ì€ íŒŒì¼ë¶€í„° ìš°ì„  ì²˜ë¦¬
        sorted_files = sorted(files, key=lambda f: len(f.get('content', '')))
        
        for file_info in sorted_files:
            content = file_info.get('content', '')
            file_tokens = TokenManager.estimate_tokens(content)
            
            if total_tokens + file_tokens > max_tokens:
                # ë‚¨ì€ í† í°ìœ¼ë¡œ íŒŒì¼ ë‚´ìš© ì¶•ì•½
                remaining_tokens = max_tokens - total_tokens
                if remaining_tokens > 100:  # ìµœì†Œ 100í† í°ì€ ìˆì–´ì•¼ ì˜ë¯¸ìˆìŒ
                    file_info['content'] = TokenManager.truncate_content(content, remaining_tokens)
                    optimized_files.append(file_info)
                break
            
            optimized_files.append(file_info)
            total_tokens += file_tokens
        
        logger.info(f"ğŸ“Š íŒŒì¼ ìµœì í™”: {len(files)} â†’ {len(optimized_files)}ê°œ, ì˜ˆìƒ í† í°: {total_tokens}")
        return optimized_files

class GitFileTracker:
    """Git ì €ì¥ì†Œ íŒŒì¼ ì¶”ì  ë° ê´€ë¦¬"""
    
    def __init__(self, repo_path: str = "."):
        self.repo_path = Path(repo_path)
        self.tracking_file = self.repo_path / ".gpt_tracking.json"
    
    def should_ignore(self, path: Path) -> bool:
        """íŒŒì¼/ë””ë ‰í† ë¦¬ê°€ ë¬´ì‹œ ëŒ€ìƒì¸ì§€ í™•ì¸"""
        path_str = str(path)
        return any(pattern in path_str for pattern in IGNORE_PATTERNS)
    
    def get_all_tracked_files(self) -> List[Path]:
        """ì¶”ì  ëŒ€ìƒ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        tracked_files = []
        
        for pattern in TRACKED_PATTERNS:
            for file_path in self.repo_path.rglob(pattern):
                if file_path.is_file() and not self.should_ignore(file_path):
                    tracked_files.append(file_path)
        
        return tracked_files
    
    def load_tracking_info(self) -> Dict:
        """ê¸°ì¡´ ì¶”ì  ì •ë³´ ë¡œë“œ"""
        if not self.tracking_file.exists():
            return {}
        
        try:
            with open(self.tracking_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        except Exception as e:
            logger.warning(f"âš ï¸ ì¶”ì  íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return {}
    
    def save_tracking_info(self, tracking_info: Dict):
        """ì¶”ì  ì •ë³´ ì €ì¥"""
        try:
            with open(self.tracking_file, 'w', encoding='utf-8') as f:
                json.dump(tracking_info, f, indent=2, ensure_ascii=False)
            logger.info(f"ğŸ’¾ ì¶”ì  ì •ë³´ ì €ì¥ ì™„ë£Œ: {len(tracking_info)}ê°œ íŒŒì¼")
        except Exception as e:
            logger.error(f"âŒ ì¶”ì  ì •ë³´ ì €ì¥ ì‹¤íŒ¨: {e}")
    
    def get_changed_files(self) -> List[Dict]:
        """ë³€ê²½ëœ íŒŒì¼ ëª©ë¡ê³¼ ë‚´ìš© ë°˜í™˜"""
        current_files = self.get_all_tracked_files()
        tracking_info = self.load_tracking_info()
        changed_files = []
        
        for file_path in current_files:
            try:
                # íŒŒì¼ ë‚´ìš© ì½ê¸°
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                relative_path = str(file_path.relative_to(self.repo_path))
                file_hash = hash(content)
                
                # ë³€ê²½ ì—¬ë¶€ í™•ì¸
                if relative_path not in tracking_info or tracking_info[relative_path] != file_hash:
                    changed_files.append({
                        'path': relative_path,
                        'content': content,
                        'size': len(content),
                        'is_new': relative_path not in tracking_info
                    })
                    tracking_info[relative_path] = file_hash
            
            except Exception as e:
                logger.warning(f"âš ï¸ íŒŒì¼ ì²˜ë¦¬ ì‹¤íŒ¨ {file_path}: {e}")
        
        # ì¶”ì  ì •ë³´ ì—…ë°ì´íŠ¸
        self.save_tracking_info(tracking_info)
        return changed_files

class GPTPatcher:
    """GPT ê¸°ë°˜ ìë™ ì½”ë“œ íŒ¨ì¹˜"""
    
    def __init__(self, api_key: str):
        self.client = openai.OpenAI(api_key=api_key)
        self.token_manager = TokenManager()
        logger.info("âœ… OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def create_system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        return """ë‹¹ì‹ ì€ ì „ë¬¸ ì½”ë“œ ê°œë°œìì…ë‹ˆë‹¤. ë‹¤ìŒ ê·œì¹™ì„ ì¤€ìˆ˜í•˜ì„¸ìš”:

1. **JSON í˜•ì‹ ì‘ë‹µ**: ë°˜ë“œì‹œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µ
```json
{
  "plan": "ìˆ˜í–‰í•  ì‘ì—… ê³„íš",
  "files": [
    {
      "path": "íŒŒì¼ê²½ë¡œ",
      "action": "create|modify|delete",
      "content": "ì „ì²´ íŒŒì¼ ë‚´ìš© (create/modifyì‹œ)",
      "reason": "ì‘ì—… ì´ìœ "
    }
  ],
  "summary": "ì‘ì—… ìš”ì•½"
}
```

2. **íŒŒì¼ ì²˜ë¦¬ ê·œì¹™**:
   - create: ìƒˆ íŒŒì¼ ìƒì„±
   - modify: ê¸°ì¡´ íŒŒì¼ ìˆ˜ì • (ì „ì²´ ë‚´ìš© ë®ì–´ì“°ê¸°)
   - delete: íŒŒì¼ ì‚­ì œ

3. **ì½”ë“œ í’ˆì§ˆ**:
   - ì—ëŸ¬ ì²˜ë¦¬ í•„ìˆ˜ (try/except)
   - ë¡œê¹… ì¶”ê°€
   - ì£¼ì„ìœ¼ë¡œ ë™ì‘ ì„¤ëª…
   - ê¸°ì¡´ ê¸°ëŠ¥ ë³´ì¡´

4. **ì•ˆì „ì¥ì¹˜**:
   - ì¤‘ìš” íŒŒì¼ ìˆ˜ì •ì‹œ ë°±ì—… ê³ ë ¤
   - í˜¸í™˜ì„± ìœ ì§€
   - í…ŒìŠ¤íŠ¸ ê°€ëŠ¥í•œ êµ¬ì¡°"""
    
    def create_user_prompt(self, instructions: str, files: List[Dict]) -> str:
        """ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ ìƒì„±"""
        # íŒŒì¼ ì •ë³´ ìš”ì•½
        files_summary = []
        for file_info in files:
            status = "ìƒˆ íŒŒì¼" if file_info.get('is_new') else "ìˆ˜ì •ë¨"
            size_kb = file_info['size'] / 1024
            files_summary.append(f"- {file_info['path']} ({status}, {size_kb:.1f}KB)")
        
        prompt = f"""## ì‘ì—… ì§€ì‹œë¬¸
{instructions}

## í˜„ì¬ íŒŒì¼ ìƒíƒœ
{chr(10).join(files_summary)}

## íŒŒì¼ ë‚´ìš©
"""
        
        # íŒŒì¼ ë‚´ìš© ì¶”ê°€
        for file_info in files[:10]:  # ìµœëŒ€ 10ê°œ íŒŒì¼ë§Œ í¬í•¨
            prompt += f"""
### {file_info['path']}
```
{file_info['content']}
```
"""
        
        return prompt
    
    def call_gpt_api(self, instructions: str, files: List[Dict]) -> Optional[Dict]:
        """GPT API í˜¸ì¶œ"""
        # í† í° ìµœì í™”
        available_tokens = MAX_CONTEXT_TOKENS - 1000  # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë“±ì„ ìœ„í•œ ì—¬ìœ 
        optimized_files = self.token_manager.optimize_file_list(files, available_tokens)
        
        system_prompt = self.create_system_prompt()
        user_prompt = self.create_user_prompt(instructions, optimized_files)
        
        for attempt in range(RETRY_ATTEMPTS):
            try:
                logger.info(f"ğŸ¤– GPT API í˜¸ì¶œ ì¤‘... (ì‹œë„ {attempt + 1}/{RETRY_ATTEMPTS})")
                
                response = self.client.chat.completions.create(
                    model=OPENAI_MODEL,
                    messages=[
                        {"role": "system", "content": system_prompt},
                        {"role": "user", "content": user_prompt}
                    ],
                    max_tokens=MAX_COMPLETION_TOKENS,
                    temperature=0.3
                )
                
                content = response.choices[0].message.content.strip()
                
                # JSON íŒŒì‹± ì‹œë„
                try:
                    # ì½”ë“œ ë¸”ë¡ì´ ìˆë‹¤ë©´ ì œê±°
                    if "```json" in content:
                        content = content.split("```json")[1].split("```")[0].strip()
                    elif "```" in content:
                        content = content.split("```")[1].split("```")[0].strip()
                    
                    result = json.loads(content)
                    logger.info("âœ… GPT API í˜¸ì¶œ ì„±ê³µ")
                    return result
                
                except json.JSONDecodeError as e:
                    logger.error(f"âŒ JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
                    logger.error(f"ì‘ë‹µ ë‚´ìš©: {content[:500]}...")
                    return None
            
            except Exception as e:
                logger.warning(f"âš ï¸ ì‹œë„ {attempt + 1}: LLM í˜¸ì¶œ ì‹¤íŒ¨ - {e}")
                if attempt < RETRY_ATTEMPTS - 1:
                    time.sleep(RETRY_DELAY)
        
        logger.error("âŒ ERROR: GPT API í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨")
        return None
    
    def execute_file_operations(self, operations: List[Dict]) -> bool:
        """íŒŒì¼ ì‘ì—… ì‹¤í–‰"""
        success_count = 0
        
        for op in operations:
            try:
                path = Path(op['path'])
                action = op['action']
                
                if action == "create" or action == "modify":
                    # ë””ë ‰í† ë¦¬ ìƒì„±
                    path.parent.mkdir(parents=True, exist_ok=True)
                    
                    # íŒŒì¼ ì“°ê¸°
                    with open(path, 'w', encoding='utf-8') as f:
                        f.write(op['content'])
                    
                    logger.info(f"âœ… {action}: {path}")
                    success_count += 1
                
                elif action == "delete":
                    if path.exists():
                        path.unlink()
                        logger.info(f"ğŸ—‘ï¸ ì‚­ì œ: {path}")
                        success_count += 1
                    else:
                        logger.warning(f"âš ï¸ ì‚­ì œ ëŒ€ìƒ ì—†ìŒ: {path}")
                
            except Exception as e:
                logger.error(f"âŒ íŒŒì¼ ì‘ì—… ì‹¤íŒ¨ {op['path']}: {e}")
        
        logger.info(f"ğŸ“Š íŒŒì¼ ì‘ì—… ì™„ë£Œ: {success_count}/{len(operations)} ì„±ê³µ")
        return success_count > 0

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    try:
        # í™˜ê²½ ë³€ìˆ˜ í™•ì¸
        api_key = os.getenv("OPENAI_API_KEY")
        if not api_key:
            logger.error("âŒ OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False
        
        instructions = os.getenv("USER_INSTRUCTIONS", "")
        if not instructions:
            logger.error("âŒ USER_INSTRUCTIONS í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
            return False
        
        logger.info("ğŸš€ GPT ìë™ ì½”ë“œ ìˆ˜ì • ì‹œì‘")
        logger.info("=" * 50)
        logger.info(f"ğŸ“ ì‚¬ìš©ì ì§€ì‹œë¬¸: {instructions[:100]}...")
        
        # íŒŒì¼ ì¶”ì  ì‹œì‘
        tracker = GitFileTracker()
        changed_files = tracker.get_changed_files()
        
        if not changed_files:
            logger.info("ğŸ“‚ ë³€ê²½ëœ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            # ê¸°ë³¸ í…ŒìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
            test_content = f"""# GPT ìë™ ìˆ˜ì • í…ŒìŠ¤íŠ¸
# ìƒì„± ì‹œê°„: {time.strftime('%Y-%m-%d %H:%M:%S')}
# ì§€ì‹œë¬¸: {instructions[:100]}...

print("GPT ìë™ ìˆ˜ì • í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
"""
            changed_files = [{
                'path': f'gpt_test_{int(time.time())}.py',
                'content': test_content,
                'size': len(test_content),
                'is_new': True
            }]
        
        logger.info(f"ğŸ“‚ ì²˜ë¦¬í•  íŒŒì¼ {len(changed_files)}ê°œ í™•ì¸")
        
        # GPT íŒ¨ì¹˜ ì‹¤í–‰
        patcher = GPTPatcher(api_key)
        result = patcher.call_gpt_api(instructions, changed_files)
        
        if not result:
            logger.error("âŒ GPT API í˜¸ì¶œ ì‹¤íŒ¨")
            return False
        
        # íŒŒì¼ ì‘ì—… ì‹¤í–‰
        if 'files' in result and result['files']:
            success = patcher.execute_file_operations(result['files'])
            
            if success:
                logger.info("âœ… ëª¨ë“  ì‘ì—…ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤")
                logger.info(f"ğŸ“‹ ì‘ì—… ìš”ì•½: {result.get('summary', 'N/A')}")
                return True
            else:
                logger.error("âŒ íŒŒì¼ ì‘ì—… ì¤‘ ì˜¤ë¥˜ ë°œìƒ")
                return False
        else:
            logger.warning("âš ï¸ ìˆ˜í–‰í•  íŒŒì¼ ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤")
            return True
    
    except Exception as e:
        logger.error(f"âŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        return False

if __name__ == "__main__":
    success = main()
    exit(0 if success else 1)
